{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "animeGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "euny",
   "language": "python",
   "display_name": "euny"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "! wget -O anime-gan.zip https://github.com/ptran1203/pytorch-animeGAN/releases/download/v1.0/dataset_v1.zip\n",
    "! unzip anime-gan.zip -d /content"
   ],
   "metadata": {
    "id": "z058W0CJsVnq",
    "outputId": "2291c522-683c-4870-af21-58c460e41bba",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n",
      "'unzip'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rvh6-cYkHY90",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# from google.colab import drive, output\n",
    "import torch\n",
    "dv = torch.cuda.get_device_name(0)\n",
    "print(dv)\n",
    "\n",
    "# drive.mount('/content/drive', force_remount=False)\n",
    "repo = \"Pytorch-animeGAN\"\n",
    "%cd \"/content\"\n",
    "!rm -rf {repo}\n",
    "!git clone https://github.com/ptran1203/{repo}\n",
    "%cd {repo}\n",
    "# output.clear()"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "[WinError 2] 지정된 파일을 찾을 수 없습니다: '/content'\n",
      "C:\\Users\\incla\\Desktop\\pytorch-animeGAN-master\\pytorch-animeGAN-master\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\incla\\Desktop\\pytorch-animeGAN-master\\pytorch-animeGAN-master\\Pytorch-animeGAN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Pytorch-animeGAN'...\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "x0_9-Gd3AZKk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import os\n",
    "import urllib\n",
    "\n",
    "data_path = 'anime-gan.zip'\n",
    "dataset_url = 'https://github.com/ptran1203/pytorch-animeGAN/releases/download/v1.0/dataset_v1.zip'\n",
    "\n",
    "if not os.path.exists(\"/content/dataset\"):\n",
    "    !wget -O {data_path} {dataset_url}\n",
    "    !unzip {data_path} -d /content\n",
    "    !rm {data_path}\n",
    "\n",
    "    if not os.path.exists(\"/content/dataset\"):\n",
    "        raise ValueError(f\"Download Failed, {data_path}\")\n",
    "\n",
    "output.clear()"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n",
      "'unzip'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n",
      "'rm'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Download Failed, anime-gan.zip",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_11492\\2441951216.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexists\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"/content/dataset\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 13\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"Download Failed, {data_path}\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     14\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[0moutput\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclear\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Download Failed, anime-gan.zip"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "62WdajGhbB2h",
    "outputId": "f28a268f-f2fc-4664-b2ab-5598ad8c9de2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "working_dir = '/content/drive/MyDrive/animeGAN'\n",
    "ckp_dir = f'{working_dir}/checkpoints'\n",
    "save_img_dir = f'{working_dir}/generated_samples'\n",
    "print(f\"You're running on {dv}\")"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "You're running on Tesla T4\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cn88CEIiHWE3",
    "outputId": "28d7df7e-ed8e-4af6-ebf4-0c954f36147a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "!python3 train.py --dataset 'Shinkai'\\\n",
    "                  --batch 6\\\n",
    "                  --debug-samples 0\\\n",
    "                  --init-epochs 10\\\n",
    "                  --checkpoint-dir {ckp_dir}\\\n",
    "                  --save-image-dir {save_img_dir}\\\n",
    "                  --save-interval 1\\\n",
    "                  --gan-loss lsgan\\\n",
    "                  --init-lr 0.0001\\\n",
    "                  --lr-g 0.00002\\\n",
    "                  --lr-d 0.00004\\\n",
    "                  --wadvd 10.0\\\n",
    "                  --wadvg 10.0\\\n",
    "                  --wcon 1.5\\\n",
    "                  --wgra 3.0\\\n",
    "                  --wcol 70.0\\\n",
    "                  --resume GD\\\n",
    "                  # --use_sn\\"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# ==== Train Config ==== #\n",
      "dataset Shinkai\n",
      "data_dir /content/dataset\n",
      "epochs 100\n",
      "init_epochs 10\n",
      "batch_size 6\n",
      "checkpoint_dir /content/drive/MyDrive/animeGAN/checkpoints\n",
      "save_image_dir /content/drive/MyDrive/animeGAN/generated_samples\n",
      "gan_loss lsgan\n",
      "resume GD\n",
      "use_sn False\n",
      "save_interval 1\n",
      "debug_samples 0\n",
      "lr_g 2e-05\n",
      "lr_d 4e-05\n",
      "init_lr 0.0001\n",
      "wadvg 10.0\n",
      "wadvd 10.0\n",
      "wcon 1.5\n",
      "wgra 3.0\n",
      "wcol 70.0\n",
      "d_layers 3\n",
      "d_noise False\n",
      "==========================\n",
      "* /content/drive/MyDrive/animeGAN/generated_samples does not exist, creating...\n",
      "* /content/drive/MyDrive/animeGAN/checkpoints does not exist, creating...\n",
      "Init models...\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
      "100% 548M/548M [00:06<00:00, 86.2MB/s]\n",
      "Compute mean (R, G, B) from 1650 images\n",
      "100% 1650/1650 [00:05<00:00, 282.25it/s]\n",
      "Mean(B, G, R) of Shinkai are [-4.30144704 -3.32730112  7.62874817]\n",
      "Dataset: real 6656 style 1650, smooth 1650\n",
      "Could not load checkpoint, train from scratch [Errno 2] No such file or directory: '/content/drive/MyDrive/animeGAN/checkpoints/generator_Shinkai.pth'\n",
      "Epoch 0/100\n",
      "[Init Training G] content loss: 4.216522:   4% 44/1110 [00:45<14:53,  1.19it/s]"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "! pip install imageio-ffmpeg"
   ],
   "metadata": {
    "id": "DDQ6sri5r35u",
    "outputId": "bebdc7df-50f7-44f2-c65d-5255e903360a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting imageio-ffmpeg\n",
      "  Downloading imageio_ffmpeg-0.4.7-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "\u001B[K     |████████████████████████████████| 26.9 MB 1.5 MB/s \n",
      "\u001B[?25hInstalling collected packages: imageio-ffmpeg\n",
      "Successfully installed imageio-ffmpeg-0.4.7\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "f3BSs5dkAFXP",
    "outputId": "b79ad2f8-2873-4d17-af7e-7501edc07aee",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from inference import Transformer\n",
    "transformer = Transformer(ckp_dir + '/generator_Shinkai.pth')"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-7-6c5a37d7d085>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0minference\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mTransformer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mtransformer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTransformer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mckp_dir\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m'/generator_Shinkai.pth'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/content/Pytorch-animeGAN/inference.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, weight, add_mean)\u001B[0m\n\u001B[1;32m     27\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mG\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mG\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 29\u001B[0;31m         \u001B[0mload_weight\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mG\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     30\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mG\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meval\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/content/Pytorch-animeGAN/utils/common.py\u001B[0m in \u001B[0;36mload_weight\u001B[0;34m(model, weight)\u001B[0m\n\u001B[1;32m     51\u001B[0m         \u001B[0mweight\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_download_weight\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 53\u001B[0;31m     \u001B[0mcheckpoint\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m  \u001B[0mmap_location\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'cuda:0'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_available\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     54\u001B[0m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m  \u001B[0mmap_location\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'cpu'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     55\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_state_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcheckpoint\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'model_state_dict'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstrict\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[1;32m    697\u001B[0m         \u001B[0mpickle_load_args\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'encoding'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'utf-8'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    698\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 699\u001B[0;31m     \u001B[0;32mwith\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'rb'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mopened_file\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    700\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0m_is_zipfile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopened_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    701\u001B[0m             \u001B[0;31m# The zipfile reader is going to advance the current file position.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001B[0m in \u001B[0;36m_open_file_like\u001B[0;34m(name_or_buffer, mode)\u001B[0m\n\u001B[1;32m    228\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    229\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0m_is_path\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 230\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    231\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    232\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;34m'w'\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, name, mode)\u001B[0m\n\u001B[1;32m    209\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_opener\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    210\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 211\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_open_file\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    212\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    213\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__exit__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/animeGAN/checkpoints/generator_Shinkai.pth'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0hTIi5dvkzAZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def random_img(img_dir):\n",
    "    # p = '/content/test_4.png'\n",
    "    p = os.path.join(img_dir, random.choice(os.listdir(img_dir)))\n",
    "    return cv2.imread(p)[:, :, ::-1]\n",
    "\n",
    "image = random_img('/content/dataset/test/HR_photo')\n",
    "image = cv2.resize(image, (768, 512))\n",
    "\n",
    "anime_img = (transformer.transform(image) + 1) / 2\n",
    "\n",
    "fig = plt.figure(figsize=(18, 25))\n",
    "fig.add_subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "fig.add_subplot(1, 2, 2)\n",
    "plt.imshow(anime_img[0])\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l1STqcCd4VcQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Inference Image"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nxiL259r4Uqi",
    "outputId": "38181834-882f-42c4-c5ac-3674d91e2c84",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# !python3 inference_image.py --checkpoint {ckp_dir}/generator_Shinkai.pth\\\n",
    "#                             --src /content/dataset/test/HR_photo\\\n",
    "#                             --dest {working_dir}/inference_shinkai"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Weight loaded, ready to predict\n",
      "Found 45 images in /content/dataset/test/HR_photo\n",
      "100% 45/45 [00:24<00:00,  1.82it/s]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vb_Jxx7gO-vp",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Inference video"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0WFuk0cfPAzl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# !python3 inference_video.py --checkpoint {ckp_dir}\\\n",
    "#                             --src /content/test_vid_3.mp4\\\n",
    "#                             --dest /content/test_vid_3_anime.mp4\\\n",
    "#                             --batch-size 2"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}